{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COM-415 Final Project by Nicola Figari and Dohun Jeong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These should be already installed on your computer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.fft as fft\n",
    "import scipy as scipy\n",
    "import scipy.io.wavfile as wav\n",
    "import scipy.signal as sig\n",
    "import time\n",
    "import timeit\n",
    "#import neopixels\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import Audio\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# These may need to be installed\n",
    "import pylab as py\n",
    "from pylab import imread,subplot,imshow,show \n",
    "from ipywidgets import widgets #pip install ipywidgets\n",
    "import pygame # pip install pygame\n",
    "from pywt import _multilevel # pip install pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function takes file name string and imports audio file in the same directory\n",
    "# returns, sampling rate and the audio file.\n",
    "def importAudio(filename):\n",
    "    return wav.read(filename)\n",
    "# This function takes in a 2-element array-like datatype as 'seconds'. The first element indicate the starting time\n",
    "# and the second element indicate the end time of the original audio file that needs to be clipped.\n",
    "def clipAudio(fs, audio, seconds):\n",
    "    return audio[seconds[0]*fs:seconds[1]*fs]\n",
    "\n",
    "def plotAudio(filename):\n",
    "    [fs, x] = wav.read(filename)\n",
    "    m = x.shape[0]\n",
    "    t = np.linspace(0.0, m/fs, m)\n",
    "    fig, axes = plt.subplots(1, 1)\n",
    "    axes.plot(t, x,'r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filterbank algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filterbank(signal, bandlimits, Fs):\n",
    "\n",
    "    transform = fft.fft(signal)\n",
    "    n = len(transform)\n",
    "    n_bands = len(bandlimits)\n",
    "    bl = np.zeros((n_bands))\n",
    "    br = np.zeros((n_bands))\n",
    "    for i in range(n_bands-1):\n",
    "        bl[i] = (np.floor(bandlimits[i]/Fs*n/2)+1)\n",
    "        br[i] = (np.floor(bandlimits[i+1]/Fs*n/2))\n",
    "    bl = bl.astype(int)\n",
    "    br = br.astype(int)\n",
    "    bl[n_bands-1] = np.floor(bandlimits[n_bands-1]/Fs*n/2)+1\n",
    "    br[n_bands-1] = np.floor(n/2)\n",
    "    #print(bl, br, bandlimits[n_bands-1]/Fs*n/2+1, n/2)\n",
    "\n",
    "    output = np.zeros((n,n_bands))\n",
    "\n",
    "    for i in range(n_bands):\n",
    "        output[bl[i]:br[i],i] = transform[bl[i]:br[i]]\n",
    "        output[n+1-br[i]:n+1-bl[i],i] = transform[n+1-br[i]:n+1-bl[i]]\n",
    "\n",
    "    output[0,0]=0;\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hwindow(signal, winlength, bandlimits, Fs):\n",
    "\n",
    "    n = len(signal)\n",
    "    n_bands = len(bandlimits)\n",
    "    han_len = (winlength*2*Fs)//1\n",
    "\n",
    "    hann = np.zeros((n))\n",
    "\n",
    "    for a in range(han_len):\n",
    "        hann[a] = np.square((np.cos(a*np.pi/han_len/2)))\n",
    "\n",
    "    wave = np.real(fft.ifft(signal, axis=0))\n",
    "    wave = np.absolute(wave)\n",
    "    wave = fft.fft(wave, axis=0)\n",
    "    wave = np.multiply(wave, fft.fft(hann)[:, np.newaxis])\n",
    "    wave = np.real(fft.ifft(wave, axis=0))\n",
    "    return wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # Input: audio is a 2D np.array, with each column being a frequency band\n",
    "def diffrect(audio):\n",
    "        audio = np.diff(audio, axis=0)\n",
    "        audio[audio < 0] = 0\n",
    "        return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combfilter(audio, accuracy, minBPM, maxBPM, numBands, maxfreq):\n",
    "    length = audio.shape[0]\n",
    "    maxEnergy = 0\n",
    "    npulse = 3\n",
    "    for bpm in range(minBPM, maxBPM) :#modify loop to modify accuracy\n",
    "        # try comb with given bpm\n",
    "        period = (np.floor(60/bpm*2*maxfreq)).astype(int)\n",
    "\n",
    "        result = np.zeros(((length+period*(npulse)).astype(int),numBands))\n",
    "        for i in range(npulse):\n",
    "            result[i*period:i*period+length] += audio\n",
    "        energy = np.sum(np.abs(result)**2)\n",
    "\n",
    "        if (energy > maxEnergy):\n",
    "            currBPM = bpm\n",
    "            maxEnergy = energy\n",
    "    return currBPM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy algorithm\n",
    "\n",
    "The algorithm divides the data into blocks of 1000 samples and compares the energy of a block $E_j$ with the energy of a window of blocks $E_{avg}$ (48 blocks) to which the block itself belongs. The energy of a block is used to detect a beat. If the energy $E_j$ of a block is above a certain threshold then the block is considered to be a beat.\n",
    "$$E_j = \\sum_{i=0}^{1000}f(i)$$\n",
    "\n",
    "$$E_{avg} = \\frac{1}{48}\\sum_{j=1}^{48}E_j$$\n",
    "\n",
    "The threshold can be defined in two different ways: \n",
    "1. We consider the avarage energy of a window of blocks as the threshold \n",
    "$$E_j > E_{avg}$$\n",
    "2. We take the avarage energy of a windows and weight it by a factor $c$ \n",
    "$$E_j > cE_{avg}$$\n",
    "\n",
    "The factor $c$ is defined as follows: \n",
    "$$c=âˆ’0.0025714var(E)+1.5142857$$\n",
    "\n",
    "$$var(E) = \\frac{1}{48}\\sum_{j=0}^{48}(E_{avg} - E_j)^2$$\n",
    "\n",
    "$c$ depends on the energy variance of the window of blocks and quanties how marked the beats of the song are. The bigger the variance, the smaller the weight. \n",
    "\n",
    "Once we detected the blocks which correspond to beats and the ones which don't, we assign 1 to the beat blocks and 0 to the non beat blocks. We then pass the resulting signal through a comb filter that gives us the BPM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def energy_beat(audio, fs):\n",
    "    signal = audio.astype(float)\n",
    "    n = np.floor(len(signal)/48000)\n",
    "    signal = signal[0:(np.int(n)*48000)]\n",
    "    signal = np.power(signal,2)\n",
    "    inst = np.reshape(signal, (np.int(np.ceil(len(signal)/1000)),1000))\n",
    "    Ej = np.sum(inst,1)\n",
    "    a = np.reshape(Ej,(np.int((len(Ej)/48)),48))\n",
    "    avgE = np.mean(a,1)\n",
    "    avgE = np.tile(avgE,(48,1))\n",
    "    avgE = np.reshape(avgE,len(Ej),'F')\n",
    "    beat = np.greater(Ej, avgE)\n",
    "    beat = beat.astype(int)\n",
    "    beats = np.tile(beat,(1000,1))\n",
    "    beats = np.reshape(beats,len(beat)*1000,'F')\n",
    "    return beats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def energy_beat_w_variance(audio, fs):\n",
    "    signal = audio.astype(float)\n",
    "    n = np.floor(len(signal)/48000)\n",
    "    signal = signal[0:(np.int(n)*48000)]\n",
    "    signal = np.power(signal,2)\n",
    "    inst = np.reshape(signal, (np.int(np.ceil(len(signal)/1000)),1000))\n",
    "    Ej = np.sum(inst,1)\n",
    "    a = np.reshape(Ej,(np.int((len(Ej)/48)),48))\n",
    "    avgE = np.mean(a,1)\n",
    "    avgE = np.tile(avgE,(48,1))\n",
    "    avgE = np.reshape(avgE,len(Ej),'F')\n",
    "    b = (avgE - Ej)**2\n",
    "    d = np.reshape(b,(len(b)//48,48))\n",
    "\n",
    "    var = np.var(inst,1)\n",
    "\n",
    "    c = (-0.0025714)*var + 1.5142857\n",
    "    beat = np.greater(Ej, c*avgE)\n",
    "    beat = beat.astype(int)\n",
    "    beats = np.tile(beat,(1000,1))\n",
    "    beats = np.reshape(beats,len(beat)*1000,'F')\n",
    "\n",
    "    return beats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combfilterEnergy(audio, accuracy, minBPM, maxBPM, maxfreq):\n",
    "    length = audio.shape[0]\n",
    "    maxEnergy = 0\n",
    "    npulse = 3\n",
    "    for bpm in range(minBPM, maxBPM) :#modify loop to modify accuracy\n",
    "        # try comb with given bpm\n",
    "        period = (np.floor(60/bpm*2*maxfreq)).astype(int)\n",
    "\n",
    "        result = np.zeros((length+period*(npulse)).astype(int))\n",
    "        for i in range(npulse):\n",
    "            result[i*period:i*period+length] += audio\n",
    "        energy = np.sum(np.abs(result)**2)\n",
    "\n",
    "        if (energy > maxEnergy):\n",
    "            currBPM = bpm\n",
    "            maxEnergy = energy\n",
    "    return currBPM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete Wavelet Transform Method - Not fully implemented\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DWT(fs, audio):\n",
    "    cA5, cD5, cD4, cD3, cD2, cD1, cD0 = _multilevel.wavedec(audio, 'db1', level=6)\n",
    "    transform = np.zeros((len(audio)//2,6))\n",
    "    transform[0:len(cD0),0] = cD0\n",
    "    transform[0:len(cD1),1] = cD1\n",
    "    transform[0:len(cD2),2] = cD2\n",
    "    transform[0:len(cD3),3] = cD3\n",
    "    transform[0:len(cD4),4] = cD4\n",
    "    transform[0:len(cD5),5] = cD5\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LPF(audio):\n",
    "    return sig.lfilter([0.01],[1.99],audio,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FWR(audio):\n",
    "    return np.absolute(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def downsample(audio):\n",
    "    for i in range(6):\n",
    "        np.delete(audio[:,i], np.arange(0, len(audio[:,i]), 2**(6-i)))\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(audio):\n",
    "    for i in range(6):\n",
    "        audio[:,i] -= np.average(audio[:,i])\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def autocorrelate(fs, audio):\n",
    "    output = np.zeros(len(audio))\n",
    "    audio = np.sum(audio, axis=-1)\n",
    "    #for i in range(len(audio)):\n",
    "     #   delayedAudio = np.append(np.zeros(i), audio)\n",
    "      #  audioPad = np.append(audio, np.zeros(i))\n",
    "       # output[i] = np.sum(audioPad*delayedAudio)\n",
    "    return np.abs(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change of Spectrum Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spectrumMethod(fs, audio):\n",
    "    audioLength = len(audio)\n",
    "    f, t, Zxx = sig.stft(audio, fs)\n",
    "    Zxx =  np.log(1+1000*np.abs(Zxx) )\n",
    "    audio = np.diff(Zxx, axis=1) #differentiate\n",
    "    audio = np.sum(audio, axis=0) #accumulate\n",
    "    audio -= np.average(audio) #normalize\n",
    "    audio = sig.resample(audio, audioLength) #back to the same time rate\n",
    "    bpm = combfilterEnergy(np.real(audio), 1, 60, 180, fs)\n",
    "    print(bpm)\n",
    "    return bpm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filterbankMethod (fs, audio):\n",
    "    bandlimits = np.array([0, 200, 400, 800, 1600, 3200])\n",
    "    signal = filterbank(audio, bandlimits, fs)\n",
    "    audio = hwindow(signal, 1, bandlimits, fs)\n",
    "    audio = diffrect(audio)\n",
    "    bpm = combfilter(audio, 1, 60, 180, len(bandlimits), fs)\n",
    "    print(bpm)\n",
    "    return bpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def energyMethod (fs, audio):\n",
    "    beat = energy_beat(audio, fs)\n",
    "    beat = diffrect(beat)\n",
    "    bpm = combfilterEnergy(beat, 1, 60, 180, fs)\n",
    "    print(bpm)\n",
    "    return bpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DWTMethod (fs, audio):\n",
    "    audio = DWT(fs, audio) # cascaded Discrete Wavelet Transform, 6 bands\n",
    "    #audio = LPF(audio) # lowpass filter\n",
    "    audio = sig.hilbert(audio)\n",
    "    audio = FWR(audio) # full wave rectification\n",
    "    audio = downsample(audio)\n",
    "    audio = normalize(audio)\n",
    "    audio = autocorrelate(fs, audio)\n",
    "    bpm = combfilterEnergy(audio, 2, 120, 360, fs)\n",
    "    return bpm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GUI Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell implements the GUI for you to enjoy our demo. Continue scrolling to run the demo :-)\n",
    "im1 = imread('Tree1.png')\n",
    "im2 = imread('Tree2.png')\n",
    "\n",
    "from ipywidgets import Layout, Button, Box, FloatText, Textarea, Dropdown, Label, IntSlider, Select, VBox,IntRangeSlider\n",
    "\n",
    "form_item_layout = Layout(\n",
    "    display='flex',\n",
    "    flex_flow='row',\n",
    "    justify_content='space-between'\n",
    ")\n",
    "\n",
    "method = Dropdown(options=['Energy','Filterbank','Spectrum'])\n",
    "song = Dropdown(options=['bottle_60bpm.wav',\n",
    "                         'Music_database/Rise.wav',\n",
    "                         'Music_database/Despacito (feat. Daddy Yankee).wav',\n",
    "                         'Music_database/In the Air Tonight.wav',\n",
    "                         'Music_database/Opposite of Adults.wav',\n",
    "                         'Music_database/Reality (feat. Janieck Devy).wav',\n",
    "                         'Music_database/Rolling In the Deep.wav',\n",
    "                         'Music_database/Sofia.wav',\n",
    "                         'Music_database/Summer Paradise (feat. Sean Paul).wav',\n",
    "                         'Music_database/Sunshine Road.wav',\n",
    "                         'Music_database/Unity.wav',\n",
    "                         'Music_database/Some Nights.wav',\n",
    "                         'Music_database/American.wav',\n",
    "                         'Music_database/Gold On the Ceiling.wav',\n",
    "                         'Music_database/Ain\\'t No Love In the Heart of the City.wav',\n",
    "                         'Music_database/Lazy Bones.wav',\n",
    "                         'Music_database/Santa Claus Is Coming To Town.wav',\n",
    "                         'Music_database/Hide and Seek.wav',\n",
    "                         'Music_database/I\\'LL BE GONE.wav',\n",
    "                         'Music_database/X-Kid.wav',\n",
    "                         'Music_database/Nero\\'s Nocturne.wav',\n",
    "                         'Music_database/Highway to Hell.wav',\n",
    "                         'Music_database/Remember to Breathe.wav',\n",
    "                         'Music_database/Someone Like You.wav',\n",
    "                         'Music_database/Hollywood.wav',\n",
    "                         'Music_database/Jingle Bells (lyrics).wav',\n",
    "                         'Music_database/All I Want For Christmas Is You.wav',\n",
    "                         'Music_database/Christmas (Baby Please Come Home).wav',\n",
    "                        ])\n",
    "run_button = Button(description='Run', disabled=False,\n",
    "                                        button_style='',\n",
    "                                        tooltip='Click me',\n",
    "                                        icon='check')\n",
    "\n",
    "seconds = IntRangeSlider(\n",
    "    value=[0, 8],\n",
    "    min=0,\n",
    "    max=240,\n",
    "    step=1,\n",
    "    description='',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d',\n",
    ")\n",
    "\n",
    "form_items = [\n",
    "    Box([Label(value='Method'), method], layout=form_item_layout),\n",
    "    Box([Label(value='Song'), song], layout=form_item_layout),\n",
    "    Box([Label(value='Seconds to analyse'), seconds], layout=form_item_layout),\n",
    "    Box([run_button], layout=form_item_layout),\n",
    "\n",
    "]\n",
    "\n",
    "out = widgets.Output()\n",
    "\n",
    "outb = [\n",
    "    Box([out],layout=form_item_layout)\n",
    "]\n",
    "\n",
    "outbox = Box(outb, layout=Layout(\n",
    "    display='flex',\n",
    "    flex_flow='column',\n",
    "    border='solid 2px',\n",
    "    align_items='stretch',\n",
    "    width='50%'\n",
    "))\n",
    "\n",
    "out2 = widgets.Output()\n",
    "\n",
    "outb2 = [\n",
    "    Box([out2],layout=form_item_layout)\n",
    "]\n",
    "\n",
    "outbox2 = Box(outb2, layout=Layout(\n",
    "    display='',\n",
    "    flex_flow='column',\n",
    "    border='',\n",
    "    align_items='stretch',\n",
    "    width='50%',\n",
    "    height = '300px'\n",
    "))\n",
    "\n",
    "out3 = widgets.Output()\n",
    "\n",
    "outb3 = [\n",
    "    Box([out3],layout=form_item_layout)\n",
    "]\n",
    "\n",
    "outbox3 = Box(outb3, layout=Layout(\n",
    "    display='flex',\n",
    "    flex_flow='column',\n",
    "    border='',\n",
    "    align_items='stretch',\n",
    "    width='50%',\n",
    "))\n",
    "\n",
    "form = Box(form_items, layout=Layout(\n",
    "    display='flex',\n",
    "    flex_flow='column',\n",
    "    border='solid 2px',\n",
    "    align_items='stretch',\n",
    "    width='50%'\n",
    "))\n",
    "\n",
    "def cristmas_trees(a):\n",
    "    #try:\n",
    "    #    led_ring_address = '/dev/cu.usbmodem144301'\n",
    "    #    led_ring = neopixels.NeoPixels(usb_port=led_ring_address)\n",
    "    #except IOError:\n",
    "    #    raise IOError(\"Could not connect to LED ring!\")\n",
    "    \n",
    "    b = True\n",
    "    sleep_t = 60/a-0.051196840059710667\n",
    "    while b == True:\n",
    "        try:\n",
    "            clear_output()\n",
    "            plt.axis('off')\n",
    "            imshow(im1)\n",
    "            #led_ring.lightify_mono(rgb=[0, 150, 0])\n",
    "            show()\n",
    "            time.sleep(sleep_t)\n",
    "            clear_output()\n",
    "            plt.axis('off')\n",
    "            imshow(im2)\n",
    "            #led_ring.lightify_mono(rgb=[150, 150, 0])\n",
    "            show()\n",
    "            time.sleep(sleep_t)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            b = False\n",
    "            print('Manual break by user')\n",
    "            pygame.mixer.music.stop() \n",
    "                       \n",
    "\n",
    "def run(a):\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "        print('The detected BPM is: ')\n",
    "        [fs, audio] = importAudio(song.value)\n",
    "        if(seconds.value[1] < np.floor(len(audio)/fs)):\n",
    "            audio = clipAudio(fs, audio, seconds.value)\n",
    "        if(method.value=='Energy'):\n",
    "            a = energyMethod(fs,audio)\n",
    "        if(method.value=='Filterbank'):\n",
    "            a = filterbankMethod(fs, audio)\n",
    "        if(method.value=='Spectrum'):\n",
    "            a = spectrumMethod(fs, audio)\n",
    "    with out3:\n",
    "        pygame.mixer.init()\n",
    "        pygame.mixer.music.load(song.value)\n",
    "        pygame.mixer.music.play()  \n",
    "    with out2:\n",
    "        cristmas_trees(a)\n",
    "\n",
    "\n",
    "Beat_detection = VBox([form, outbox, outbox3, outbox2])\n",
    "            \n",
    "run_button.on_click(run)\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Program with GUI\n",
    "Finally, it's time to checkout the actual program!\n",
    "Here's how you can test the program. \n",
    "1. Run the cell below.\n",
    "2. Choose a beat detecting method from the dropdown menu\n",
    "3. Choose a song from the dropdown menu\n",
    "4. Drag the slider to specify which section of the song to analyze. As you'll see in our test, 8 second clip will suffice for most songs\n",
    "5. Enjoy the Christmas tree! Audio will start playing as soon as bpm analysis is done. To stop the music, you need to run the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70cf2a71b82d4b47ab82e92255023769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Beat_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.mixer.music.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because imshow() function takes time that we can't account for, we've fine tuned the loop's pause time to make the visuals line up with the beat. It may not work on your computer so we uploaded a video for your entertainment. Check it out in the attached files :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "1. Tzanetakis, George, and Perry Cook. \"Musical genre classification of audio signals.\" IEEE Transactions on speech and audio processing 10.5 (2002): 293-302.\n",
    "2. Scheirer, Eric D. \"Tempo and beat analysis of acoustic musical signals.\" The Journal of the Acoustical Society of America 103.1 (1998): 588-601.\n",
    "3. http://archive.gamedev.net/archive/reference/programming/features/beatdetection/index.html\n",
    "4. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
